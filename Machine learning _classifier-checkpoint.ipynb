{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K -nearest neighbour classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'C:\\\\Users\\\\user\\\\Anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\iris.csv'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n"
     ]
    }
   ],
   "source": [
    "print(iris.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "classes={0:'setosa',1:'versicolor',2:'virginica'}\n",
    "df_x=pd.DataFrame(iris.data,columns=iris.feature_names)\n",
    "df_y=pd.DataFrame(iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(df_x,df_y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>6.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "73                 6.1               2.8                4.7               1.2\n",
       "18                 5.7               3.8                1.7               0.3\n",
       "118                7.7               2.6                6.9               2.3\n",
       "78                 6.0               2.9                4.5               1.5\n",
       "76                 6.8               2.8                4.8               1.4\n",
       "31                 5.4               3.4                1.5               0.4\n",
       "64                 5.6               2.9                3.6               1.3\n",
       "141                6.9               3.1                5.1               2.3\n",
       "68                 6.2               2.2                4.5               1.5\n",
       "82                 5.8               2.7                3.9               1.2\n",
       "110                6.5               3.2                5.1               2.0\n",
       "12                 4.8               3.0                1.4               0.1\n",
       "36                 5.5               3.5                1.3               0.2\n",
       "9                  4.9               3.1                1.5               0.1\n",
       "19                 5.1               3.8                1.5               0.3\n",
       "56                 6.3               3.3                4.7               1.6\n",
       "104                6.5               3.0                5.8               2.2\n",
       "69                 5.6               2.5                3.9               1.1\n",
       "55                 5.7               2.8                4.5               1.3\n",
       "132                6.4               2.8                5.6               2.2\n",
       "29                 4.7               3.2                1.6               0.2\n",
       "127                6.1               3.0                4.9               1.8\n",
       "26                 5.0               3.4                1.6               0.4\n",
       "128                6.4               2.8                5.6               2.1\n",
       "131                7.9               3.8                6.4               2.0\n",
       "145                6.7               3.0                5.2               2.3\n",
       "108                6.7               2.5                5.8               1.8\n",
       "143                6.8               3.2                5.9               2.3\n",
       "45                 4.8               3.0                1.4               0.3\n",
       "30                 4.8               3.1                1.6               0.2"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-b515cb0f29fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mscores_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "scores={}\n",
    "scores_list=[]\n",
    "k_range=range(1,26)\n",
    "for k in k_range :\n",
    "    knn=KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(x_train,y_train)\n",
    "    y_pred=knn.predict(x_test)\n",
    "    scores[k]=metrics.accuracy_score(y_test,y_pred)\n",
    "    scores_list.append(metrics.accuracy_score(y_test,y_pred))\n",
    "classes={0:'setosa',1:'versicolor',2:'virginica'}\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "versicolor\n",
      "setosa\n",
      "virginica\n",
      "versicolor\n",
      "versicolor\n",
      "setosa\n",
      "versicolor\n",
      "virginica\n",
      "versicolor\n",
      "versicolor\n",
      "virginica\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "versicolor\n",
      "virginica\n",
      "versicolor\n",
      "versicolor\n",
      "virginica\n",
      "setosa\n",
      "virginica\n",
      "setosa\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "setosa\n",
      "setosa\n"
     ]
    }
   ],
   "source": [
    "for i in y_pred:\n",
    "    print(classes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "versicolor\n",
      "setosa\n",
      "virginica\n",
      "versicolor\n",
      "versicolor\n",
      "setosa\n",
      "versicolor\n",
      "virginica\n",
      "versicolor\n",
      "versicolor\n",
      "virginica\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "versicolor\n",
      "virginica\n",
      "versicolor\n",
      "versicolor\n",
      "virginica\n",
      "setosa\n",
      "virginica\n",
      "setosa\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "setosa\n",
      "setosa\n"
     ]
    }
   ],
   "source": [
    "y_test=pd.DataFrame(y_test)## converting multidimensional data frame to one dimensional array\n",
    "y_test=y_test.values#first take out values by this method which gives a multi dimensional array of val\n",
    "y_test=y_test.flatten()## then convert it into singledimensional using flatten method\n",
    "y_test## now it is iterative.so we cqan assign and show given values to their names.\n",
    "for i in y_test:\n",
    "    print(classes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 1.0,\n",
       " 2: 1.0,\n",
       " 3: 1.0,\n",
       " 4: 1.0,\n",
       " 5: 1.0,\n",
       " 6: 1.0,\n",
       " 7: 0.9666666666666667,\n",
       " 8: 1.0,\n",
       " 9: 1.0,\n",
       " 10: 1.0,\n",
       " 11: 1.0,\n",
       " 12: 1.0,\n",
       " 13: 1.0,\n",
       " 14: 1.0,\n",
       " 15: 1.0,\n",
       " 16: 1.0,\n",
       " 17: 1.0,\n",
       " 18: 1.0,\n",
       " 19: 1.0,\n",
       " 20: 1.0,\n",
       " 21: 1.0,\n",
       " 22: 1.0,\n",
       " 23: 1.0,\n",
       " 24: 1.0,\n",
       " 25: 1.0}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'testing accuracy')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(k_range,scores_list)\n",
    "plt.xlabel('Values for k for knn')\n",
    "plt.ylabel('testing accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "versicolor\n",
      "setosa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(x_train,y_train)\n",
    "classes={0:'setosa',1:'versicolor',2:'virginica'}\n",
    "a=[[3,4,5,2],[5,4,2,2]]\n",
    "y=knn.predict(a)\n",
    "print(classes[y[0]])\n",
    "print(classes[y[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer=load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "         1.189e-01],\n",
       "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "         8.902e-02],\n",
       "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "         8.758e-02],\n",
       "        ...,\n",
       "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "         7.820e-02],\n",
       "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "         1.240e-01],\n",
       "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "         7.039e-02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
       " 'target_names': array(['malignant', 'benign'], dtype='<U9'),\n",
       " 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry \\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 3 is Mean Radius, field\\n        13 is Radius SE, field 23 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.',\n",
       " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "        'smoothness error', 'compactness error', 'concavity error',\n",
       "        'concave points error', 'symmetry error',\n",
       "        'fractal dimension error', 'worst radius', 'worst texture',\n",
       "        'worst perimeter', 'worst area', 'worst smoothness',\n",
       "        'worst compactness', 'worst concavity', 'worst concave points',\n",
       "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
       " 'filename': 'C:\\\\Users\\\\user\\\\Anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\breast_cancer.csv'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "print(\"features:\",cancer.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cancer types: ['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "print(\"cancer types:\",cancer.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer.target.shape\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x=pd.DataFrame(cancer.data,columns=cancer.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y=pd.DataFrame(cancer.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  0\n",
       "2  0\n",
       "3  0\n",
       "4  0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(cancer.data,cancer.target,test_size=0.4,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf=svm.SVC(kernel='linear')\n",
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9605263157894737\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94        80\n",
      "           1       0.97      0.97      0.97       148\n",
      "\n",
      "    accuracy                           0.96       228\n",
      "   macro avg       0.96      0.96      0.96       228\n",
      "weighted avg       0.96      0.96      0.96       228\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K - Means classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'C:\\\\Users\\\\user\\\\Anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\iris.csv'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x=pd.DataFrame(iris.data,columns=iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                  5.1               3.5                1.4               0.2\n",
       "1                  4.9               3.0                1.4               0.2\n",
       "2                  4.7               3.2                1.3               0.2\n",
       "3                  4.6               3.1                1.5               0.2\n",
       "4                  5.0               3.6                1.4               0.2\n",
       "..                 ...               ...                ...               ...\n",
       "145                6.7               3.0                5.2               2.3\n",
       "146                6.3               2.5                5.0               1.9\n",
       "147                6.5               3.0                5.2               2.0\n",
       "148                6.2               3.4                5.4               2.3\n",
       "149                5.9               3.0                5.1               1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y=pd.DataFrame(iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "..  ..\n",
       "145  2\n",
       "146  2\n",
       "147  2\n",
       "148  2\n",
       "149  2\n",
       "\n",
       "[150 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "kmean=KMeans(n_clusters=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(df_x,df_y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "       n_clusters=3, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmean.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=kmean.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.96451613, 3.37741935, 1.46451613, 0.2483871 ],\n",
       "       [5.79555556, 2.69555556, 4.34444444, 1.41777778],\n",
       "       [6.85517241, 3.10344828, 5.70689655, 2.02068966]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmean.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 1,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "       0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "81   1\n",
       "133  2\n",
       "137  2\n",
       "75   1\n",
       "109  2\n",
       "..  ..\n",
       "71   1\n",
       "106  2\n",
       "14   0\n",
       "92   1\n",
       "102  2\n",
       "\n",
       "[105 rows x 1 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('Accuracy:',metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "msd=[]\n",
    "K=range(1,10)\n",
    "for k in K:\n",
    "    kmeanmodel=KMeans(n_clusters=k)\n",
    "    kmeanmodel.fit(df_x)\n",
    "    msd.append(kmeanmodel.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x28f3dfa7608>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(K,msd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets,svm,metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits=datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 5620\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2a3766d8888>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digits.images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure(figsize=(5,5))\n",
    "i=0\n",
    "for j in range(12):\n",
    "    plt.subplot(4,4,j+1)\n",
    "    plt.imshow(digits.images[j])\n",
    "    plt.title(digits.target[j],fontsize='8')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_x=pd.DataFrame(digits.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows  64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1     2     3     4     5    6    7    8    9   ...   54   55  \\\n",
       "0     0.0  0.0   5.0  13.0   9.0   1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1     0.0  0.0   0.0  12.0  13.0   5.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "2     0.0  0.0   0.0   4.0  15.0  12.0  0.0  0.0  0.0  0.0  ...  5.0  0.0   \n",
       "3     0.0  0.0   7.0  15.0  13.0   1.0  0.0  0.0  0.0  8.0  ...  9.0  0.0   \n",
       "4     0.0  0.0   0.0   1.0  11.0   0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "...   ...  ...   ...   ...   ...   ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1792  0.0  0.0   4.0  10.0  13.0   6.0  0.0  0.0  0.0  1.0  ...  4.0  0.0   \n",
       "1793  0.0  0.0   6.0  16.0  13.0  11.0  1.0  0.0  0.0  0.0  ...  1.0  0.0   \n",
       "1794  0.0  0.0   1.0  11.0  15.0   1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1795  0.0  0.0   2.0  10.0   7.0   0.0  0.0  0.0  0.0  0.0  ...  2.0  0.0   \n",
       "1796  0.0  0.0  10.0  14.0   8.0   1.0  0.0  0.0  0.0  2.0  ...  8.0  0.0   \n",
       "\n",
       "       56   57   58    59    60    61   62   63  \n",
       "0     0.0  0.0  6.0  13.0  10.0   0.0  0.0  0.0  \n",
       "1     0.0  0.0  0.0  11.0  16.0  10.0  0.0  0.0  \n",
       "2     0.0  0.0  0.0   3.0  11.0  16.0  9.0  0.0  \n",
       "3     0.0  0.0  7.0  13.0  13.0   9.0  0.0  0.0  \n",
       "4     0.0  0.0  0.0   2.0  16.0   4.0  0.0  0.0  \n",
       "...   ...  ...  ...   ...   ...   ...  ...  ...  \n",
       "1792  0.0  0.0  2.0  14.0  15.0   9.0  0.0  0.0  \n",
       "1793  0.0  0.0  6.0  16.0  14.0   6.0  0.0  0.0  \n",
       "1794  0.0  0.0  2.0   9.0  13.0   6.0  0.0  0.0  \n",
       "1795  0.0  0.0  5.0  12.0  16.0  12.0  0.0  0.0  \n",
       "1796  0.0  1.0  8.0  12.0  14.0  12.0  1.0  0.0  \n",
       "\n",
       "[1797 rows x 64 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y=pd.DataFrame(digits.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1792</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1793</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1794</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1795</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1796</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0     0\n",
       "1     1\n",
       "2     2\n",
       "3     3\n",
       "4     4\n",
       "...  ..\n",
       "1792  9\n",
       "1793  0\n",
       "1794  8\n",
       "1795  9\n",
       "1796  8\n",
       "\n",
       "[1797 rows x 1 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(df_x,df_y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier=svm.SVC(gamma=0.001)\n",
    "classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 3, 7, 2, 1, 5, 2, 5, 2, 1, 9, 4, 0, 4, 2, 3, 7, 8, 8, 4, 3,\n",
       "       9, 7, 5, 6, 3, 5, 6, 3, 4, 9, 1, 4, 4, 6, 9, 4, 7, 6, 6, 9, 1, 3,\n",
       "       6, 1, 3, 0, 6, 5, 5, 1, 9, 5, 6, 0, 9, 0, 0, 1, 0, 4, 5, 2, 4, 5,\n",
       "       7, 0, 7, 5, 9, 5, 5, 4, 7, 0, 4, 5, 5, 9, 9, 0, 2, 3, 8, 0, 6, 4,\n",
       "       4, 9, 1, 2, 8, 3, 5, 2, 9, 0, 4, 4, 4, 3, 5, 3, 1, 3, 5, 9, 4, 2,\n",
       "       7, 7, 4, 4, 1, 9, 2, 7, 8, 7, 2, 6, 9, 4, 0, 7, 2, 7, 5, 8, 7, 5,\n",
       "       7, 9, 0, 6, 6, 4, 2, 8, 0, 9, 4, 6, 9, 9, 6, 9, 0, 5, 5, 6, 6, 0,\n",
       "       6, 4, 3, 9, 3, 7, 7, 2, 9, 0, 4, 5, 3, 6, 5, 9, 9, 8, 4, 2, 1, 3,\n",
       "       7, 7, 2, 2, 3, 9, 8, 0, 3, 2, 2, 5, 6, 9, 9, 4, 1, 5, 4, 2, 3, 6,\n",
       "       4, 8, 5, 9, 5, 7, 8, 9, 4, 8, 1, 5, 4, 4, 9, 6, 1, 8, 6, 0, 4, 5,\n",
       "       2, 7, 4, 6, 4, 5, 6, 0, 3, 2, 3, 6, 7, 1, 5, 1, 4, 7, 6, 8, 8, 5,\n",
       "       5, 1, 6, 2, 8, 8, 9, 9, 7, 6, 2, 2, 2, 3, 4, 8, 8, 3, 6, 0, 9, 7,\n",
       "       7, 0, 1, 0, 4, 5, 1, 5, 3, 6, 0, 4, 1, 0, 0, 3, 6, 5, 9, 7, 3, 5,\n",
       "       5, 9, 9, 8, 5, 3, 3, 2, 0, 5, 8, 3, 4, 0, 2, 4, 6, 4, 3, 4, 5, 0,\n",
       "       5, 2, 1, 3, 1, 4, 1, 1, 7, 0, 1, 5, 2, 1, 2, 8, 7, 0, 6, 4, 8, 8,\n",
       "       5, 1, 8, 4, 5, 8, 7, 9, 8, 5, 0, 6, 2, 0, 7, 9, 8, 9, 5, 2, 7, 7,\n",
       "       1, 8, 7, 4, 3, 8, 3, 5, 6, 0, 0, 3, 0, 5, 0, 0, 4, 1, 2, 8, 4, 5,\n",
       "       9, 6, 3, 1, 8, 8, 4, 2, 3, 8, 9, 8, 8, 5, 0, 6, 3, 3, 7, 1, 6, 4,\n",
       "       1, 2, 1, 1, 6, 4, 7, 4, 8, 3, 4, 0, 5, 1, 9, 4, 5, 7, 6, 3, 7, 0,\n",
       "       5, 9, 7, 5, 9, 7, 4, 2, 1, 9, 0, 7, 5, 8, 3, 6, 3, 9, 6, 9, 5, 0,\n",
       "       1, 5, 5, 8, 3, 3, 6, 2, 6, 5, 5, 2, 0, 8, 7, 3, 7, 0, 2, 2, 3, 5,\n",
       "       8, 7, 3, 6, 5, 9, 9, 2, 5, 6, 3, 0, 7, 1, 1, 9, 6, 1, 1, 0, 0, 2,\n",
       "       9, 3, 9, 9, 3, 7, 7, 1, 3, 5, 4, 6, 1, 2, 1, 1, 8, 7, 6, 9, 2, 0,\n",
       "       4, 4, 8, 8, 7, 1, 3, 1, 7, 1, 3, 5, 1, 7, 0, 0, 2, 2, 6, 9, 4, 1,\n",
       "       9, 0, 6, 7, 7, 9, 5, 4, 7, 0, 7, 6])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
